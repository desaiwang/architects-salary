{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Parsing Salaries from Archinect.com</h2>\n",
    "<p>I use beautiful soup to parse survey data on Archinect.com. The data from the survey is already structured html, so I broke parsing functions into 3 parts. The sub functions deal with parsing each part.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_details1(details_1):\n",
    "    \n",
    "    # Initialize with NA or default values\n",
    "    firm_type = \"NA\"\n",
    "    firm_size = \"NA\"\n",
    "    health_insurance = \"NA\"\n",
    "    overtime = \"NA\"\n",
    "    vacation_days = \"NA\"\n",
    "    annual_bonus = \"NA\"\n",
    "\n",
    "    # Identify details in subcol-1\n",
    "    for detail in details_1:\n",
    "        if detail == \"\": #ignore empty strings\n",
    "            continue\n",
    "        elif \"People\" in detail:\n",
    "            firm_size = detail\n",
    "        elif \"Health Insurance\" in detail:\n",
    "            health_insurance = \"Yes\"\n",
    "        elif \"Overtime\" in detail:\n",
    "            overtime = detail\n",
    "        elif \"Days Vacation\" in detail:\n",
    "            vacation_days = detail.replace(\" Days Vacation\", \"\")\n",
    "        elif \"Bonus\" in detail:\n",
    "            annual_bonus = detail.replace(\"$\", \"\").replace(\" Bonus\", \"\")\n",
    "        else:\n",
    "            firm_type = detail\n",
    "    return firm_type, firm_size, health_insurance, overtime, vacation_days, annual_bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases for parse_details1 function\n",
    "#return format is: firm_type, firm_size, health_insurance, overtime, vacation_days, annual_bonus\n",
    "test_cases = [\n",
    "  (['Individual', '16-30 People', 'Health Insurance', '15 Days Vacation', '$1,000 Bonus'], (\"Individual\", \"16-30 People\", \"Yes\", \"NA\", \"15\", \"1,000\")),\n",
    "  (['Boutique', '6-10 People'], (\"Boutique\", \"6-10 People\", \"NA\", \"NA\", \"NA\", \"NA\")),\n",
    "  (['101-200 People'], (\"NA\", \"101-200 People\", \"NA\", \"NA\", \"NA\", \"NA\")),\n",
    "   (['No Overtime'], (\"NA\", \"NA\", \"NA\", \"No Overtime\", \"NA\", \"NA\")),\n",
    "   (['Corporate', '31-50 People', 'Health Insurance', 'Unpaid Overtime', '15 Days Vacation', '$10,000 Bonus'], (\"Corporate\", \"31-50 People\", \"Yes\", \"Unpaid Overtime\", \"15\", \"10,000\")),\n",
    "]\n",
    "\n",
    "# Run test cases\n",
    "for i, (input_data, expected_output) in enumerate(test_cases):\n",
    "  result = parse_details1(input_data)\n",
    "  assert result == expected_output, f\"Test case {i+1} failed: expected {expected_output}, got {result}\"\n",
    "print(\"All test cases passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_details2(details_2):\n",
    "  # Initialize with NA or default values\n",
    "  work_status = \"NA\"\n",
    "  years_of_experience = \"NA\"\n",
    "  age = \"NA\"\n",
    "  gender = \"NA\"\n",
    "  licensed = \"No\"\n",
    "\n",
    "  # Identify details in subcol-2\n",
    "  for detail in details_2:\n",
    "      if detail == \"\": #ignore empty strings\n",
    "        continue\n",
    "      elif \"time\" in detail:\n",
    "          work_status = detail\n",
    "      elif \"Freelance\" in detail:\n",
    "          work_status = detail\n",
    "      elif \"Years of Experience\" in detail:\n",
    "          #if detail is < 1 Years of Experience then\n",
    "            if \"<\" in detail:\n",
    "                years_of_experience = \"< 1\"\n",
    "            else:\n",
    "                years_of_experience = detail.split()[0]  # Assuming the first part is the number\n",
    "      elif \"Years old\" in detail:\n",
    "          age = detail.split()[0]  # Assuming the first part is the number \n",
    "      elif \"Licensed\" in detail:\n",
    "          licensed = \"Licensed\"\n",
    "      else:\n",
    "          gender = detail\n",
    "\n",
    "  return work_status, years_of_experience, age, gender, licensed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases for parse_details2 function\n",
    "test_cases_parse_details2 = [\n",
    "  (['Full-time', '3-5 Years of Experience', '26-30 Years old', 'Male', 'Licensed'], (\"Full-time\", \"3-5\", \"26-30\", \"Male\", \"Licensed\")),\n",
    "  (['Full-time', '2 Years of Experience', '21-25 Years old', 'Female'], (\"Full-time\", \"2\", \"21-25\", \"Female\", \"No\")),\n",
    "  (['', '3-5 Years of Experience', '21-25 Years old', 'Male'], (\"NA\", \"3-5\", \"21-25\", \"Male\", \"No\")),\n",
    "  (['Part-time', '8-10 Years of Experience', '26-30 Years old', 'Female'], (\"Part-time\", \"8-10\", \"26-30\", \"Female\", \"No\")),\n",
    "  (['Freelance', '11-15 Years of Experience', '46-50 Years old', 'Male', 'Licensed'], (\"Freelance\", \"11-15\", \"46-50\", \"Male\", \"Licensed\")),\n",
    "  (['Full-time', '6-7 Years of Experience', '26-30 Years old', 'Male'], (\"Full-time\", \"6-7\", \"26-30\", \"Male\", \"No\")),\n",
    "  (['Full-time', '3-5 Years of Experience', '26-30 Years old', 'Gender: Other'], (\"Full-time\", \"3-5\", \"26-30\", \"Gender: Other\", \"No\")),\n",
    "  (['Full-time', '3-5 Years of Experience', '26-30 Years old', 'Female'], (\"Full-time\", \"3-5\", \"26-30\", \"Female\", \"No\")),\n",
    "  (['Full-time', '< 1 Years of Experience', '21-25 Years old', 'Female'], (\"Full-time\", \"< 1\", \"21-25\", \"Female\", \"No\")),\n",
    "  (['Full-time', '26-30 Years of Experience', '51-55 Years old', 'Male', 'Licensed'], (\"Full-time\", \"26-30\", \"51-55\", \"Male\", \"Licensed\"))\n",
    "]\n",
    "\n",
    "# Run test cases\n",
    "for i, (input_data, expected_output) in enumerate(test_cases_parse_details2):\n",
    "  result = parse_details2(input_data)\n",
    "  assert result == expected_output, f\"Test case {i+1} failed: expected {expected_output}, got {result}\"\n",
    "print(\"All test cases for parse_details2 passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entry(entry):\n",
    "    id=entry[0]\n",
    "    soup = BeautifulSoup(entry[1], 'html.parser')\n",
    "\n",
    "    # Extract job satisfaction (from img tag)\n",
    "    job_satisfaction_img = soup.find('img', class_='emoticon')\n",
    "    if job_satisfaction_img and job_satisfaction_img.has_attr('data-original-title'):\n",
    "        job_satisfaction = job_satisfaction_img['data-original-title'].split(': ')[1]\n",
    "    else:\n",
    "        job_satisfaction = \"NA\"\n",
    "\n",
    "    # Extract salary, location, and job title (from h3 tag)\n",
    "    h3 = soup.find('h3')\n",
    "    if h3:\n",
    "        # Extract salary\n",
    "        salary_tag = h3.find('span', class_='salary')\n",
    "        #this is either $x per hour or $ per year, parse as is\n",
    "        \n",
    "        salary = re.sub(r'[^0-9,]', '', salary_tag.text) if salary_tag else \"NA\"\n",
    "        salary_unit = re.sub(r'[^a-zA-Z]', '', salary_tag.text) if salary_tag else \"NA\"\n",
    "\n",
    "        # Extract location\n",
    "        location_tag = h3.find_next('span', class_='slash').next_sibling if h3.find('span', class_='slash') else \"\"\n",
    "        location = location_tag.strip() if location_tag else \"NA\"\n",
    "\n",
    "        # Extract job title\n",
    "        job_title_tag = h3.find_all('span', class_='slash')[-1].next_sibling if h3.find_all('span', class_='slash') else \"\"\n",
    "        job_title = job_title_tag.strip() if job_title_tag else \"NA\"\n",
    "    else:\n",
    "        salary = location = job_title = \"NA\"\n",
    "\n",
    "    # Extract details from subcol-1\n",
    "    subcol_1 = soup.find('ul', class_='subcol-1')\n",
    "    details_1 = [li.get_text(strip=True) for li in subcol_1.find_all('li')] if subcol_1 else []\n",
    "    firm_type, firm_size, health_insurance, overtime, vacation_days, annual_bonus = parse_details1(details_1)\n",
    "    \n",
    "    # Extract details from subcol-2\n",
    "    subcol_2 = soup.find('ul', class_='subcol-2')\n",
    "    details_2 = [li.get_text(strip=True) for li in subcol_2.find_all('li')] if subcol_2 else []\n",
    "    work_status, years_of_experience, age, gender, licensed = parse_details2(details_2)\n",
    "\n",
    "\n",
    "    # Extract details from subcol-3\n",
    "    subcol_3 = soup.find('ul', class_='subcol-3')\n",
    "    details_3 = [li.get_text(strip=True) for li in subcol_3.find_all('li')] if subcol_3 else []\n",
    "    undergraduate_school = next((x.replace(\"UG: \", \"\").strip() for x in details_3 if x.startswith(\"UG:\")), \"NA\")\n",
    "    graduate_school = next((x.replace(\"Grad: \", \"\").strip() for x in details_3 if x.startswith(\"Grad:\")), \"NA\")\n",
    "    post_graduate_school = next((x.replace(\"PhD: \", \"\").strip() for x in details_3 if x.startswith(\"PhD:\")), \"NA\")\n",
    "\n",
    "    # Extract date stamp\n",
    "    date_stamp = soup.find('div', class_='date-stamp')\n",
    "    date = date_stamp.get_text(strip=True) if date_stamp else \"NA\"\n",
    "\n",
    "    # Construct the JSON structure\n",
    "    result = {\n",
    "        \"id\": id,\n",
    "        \"Job Satisfaction\": job_satisfaction,\n",
    "        \"Salary\": salary,\n",
    "        \"Salary Unit\": salary_unit,\n",
    "        \"Location\": location,\n",
    "        \"Job Title\": job_title,\n",
    "        \"Firm Type\": firm_type,\n",
    "        \"Firm Size\": firm_size,\n",
    "        \"Health Insurance\": health_insurance,\n",
    "        \"Overtime\": overtime,\n",
    "        \"Vacation Days\": vacation_days,\n",
    "        \"Annual Bonus\": annual_bonus,\n",
    "        \"Work Status\": work_status,\n",
    "        \"Years of Experience\": years_of_experience,\n",
    "        \"Age\": age,\n",
    "        \"Gender\": gender,\n",
    "        \"Licensed\": licensed,\n",
    "        \"Undergraduate School\": undergraduate_school,\n",
    "        \"Graduate School\": graduate_school,\n",
    "        \"Post-Graduate School\": post_graduate_school,\n",
    "        \"Date\": date\n",
    "    }\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_data():\n",
    "    url = \"https://salaries.archinect.com/salarypoll/results\" #this is the url to query\n",
    "    params = {\n",
    "        'sEcho': '2',\n",
    "        'iColumns': '2',\n",
    "        'sColumns': '',\n",
    "        'iDisplayStart': '0',\n",
    "        'iDisplayLength': '15000', #set max entries to parse\n",
    "        'mDataProp_0': '0',\n",
    "        'mDataProp_1': '1',\n",
    "        'sSearch': '',\n",
    "        'bRegex': 'false',\n",
    "        'sSearch_0': '',\n",
    "        'bRegex_0': 'false',\n",
    "        'bSearchable_0': 'false',\n",
    "        'sSearch_1': '',\n",
    "        'bRegex_1': 'false',\n",
    "        'bSearchable_1': 'true',\n",
    "        'iSortCol_0': '0',\n",
    "        'sSortDir_0': 'asc',\n",
    "        'iSortingCols': '1',\n",
    "        'bSortable_0': 'true',\n",
    "        'bSortable_1': 'false',\n",
    "        'age': '[]',\n",
    "        'gender': '[]',\n",
    "        'job_title': '[]',\n",
    "        'primary_market': '[]',\n",
    "        'experience': '[]',\n",
    "        'firm_type': '[]',\n",
    "        'firm_size': '[]',\n",
    "        'work_status': '[]',\n",
    "        'license': '[]',\n",
    "        'health_insurance': '[]',\n",
    "        'overtime': '[]',\n",
    "        'annual_bonus': '[]',\n",
    "        'sort_by': 'id',\n",
    "        'salary-range': '0;100000',\n",
    "        'range_plus': 'true',\n",
    "        'location': 'United States', #this query is for the US, you can remove this to get all data\n",
    "        'under_graduate_school': '',\n",
    "        'graduate_school': '',\n",
    "        'post_graduate_school': '',\n",
    "        'location_type': 'country',\n",
    "        'salary_time': '[]',\n",
    "        'job_satisfaction': '[]',\n",
    "        '_': '1728972672843'  # This is likely a timestamp parameter\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'X-Requested-With': 'XMLHttpRequest'\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "    parsed_data=[]\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            # Parse the JSON response\n",
    "            json_data = response.json()\n",
    "            \n",
    "            for entry in json_data['aaData']:\n",
    "                if entry[0] != \"\":  # Filter out entries with empty first elements\n",
    "                    parsed_entry = parse_entry(entry)\n",
    "                    parsed_data.append(parsed_entry)\n",
    "\n",
    "            # Convert the list of dictionaries into a pandas DataFrame\n",
    "            df = pd.DataFrame(parsed_data)\n",
    "            return df\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to decode JSON\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Uncomment the two lines below to query data and save to csv. </h4>\n",
    "<p>This can take a bit depending on your internet speed and device specs, so if you just want to analyze data please just read data from the pre-run csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to requery data, otherwise just use read_csv from \n",
    "# df = query_data()\n",
    "# df.to_csv(\"241114_archinect_salaries_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "df = pd.read_csv(\"241114_archinect_salaries_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data cleaning</h3>\n",
    "<p>Setting correct units, deleting outliers, focusing on US and full-time workers</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the prefixes in Undergraduate Schools and Graduate Schools\n",
    "df['Undergraduate School'] = df['Undergraduate School'].str.replace('UG:', '')\n",
    "df['Graduate School'] = df['Graduate School'].str.replace('Grad:', '')\n",
    "df['Post-Graduate School'] = df['Post-Graduate School'].str.replace('PhD:', '')\n",
    "\n",
    "#remove per from salary type (perhour becomes hour, peryear becomes year)\n",
    "df['Salary Unit'] = df['Salary Unit'].str.replace('per', '')\n",
    "\n",
    "#remove Gender from gender (Gender: Other becomes Other)\n",
    "df['Gender'] = df['Gender'].str.replace('Gender: ', '')\n",
    "\n",
    "#Licensed values changed to either Yes or No\n",
    "df[\"Licensed\"] = df[\"Licensed\"].str.replace('Licensed', 'Yes')\n",
    "\n",
    "#replace 40 in \"Years of Experience\" with 40+\n",
    "df['Years of Experience'] = df['Years of Experience'].replace({\n",
    "            '31- >40': '30-40',   # Replace exact match of '31- >40' to '30-40'\n",
    "            '40': '> 40'           # Replace exact match of '40' to '>40'\n",
    "        })\n",
    "\n",
    "#drop the individuals over 103 age because they seem to be spam inputs\n",
    "df = df[df['Age']!=\"103\"]\n",
    "\n",
    "#this entry represents a 18-20 year old earning 200,000+ per HOUR, definitely wrong\n",
    "df = df[df['id']!=12734]\n",
    "\n",
    "#this represents a 18-20 year old earning 355 per HOUR as the CEO of a 500+ people firm, definitely wrong\n",
    "df = df[df['id']!=2653]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have a total of 14633 entries (this is not fixed, expect higher number as more entries are added)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine the duplicates, this is probably due to people clicking submit multiple times\n",
    "duplicates = df[df.duplicated(subset=df.columns.difference(['id']), keep=False)]\n",
    "\n",
    "#remove the duplicates\n",
    "df.drop_duplicates(subset=df.columns.difference(['id']), keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noticed some weird inputs, investigating\n",
    "criteria = df[\"Post-Graduate School\"].notna() & (df['Date'] == \"Jun '24\") & (df['Location'] == \"Austin, TX, US\")\n",
    "\n",
    "#this seems like bad data, delete all that meet this criteria\n",
    "#df[criteria] (uncomment to see)\n",
    "\n",
    "# Drop the rows that match the criteria\n",
    "df.drop(df[criteria].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove ' character from Date, and extract year\n",
    "df['Date'] = df['Date'].str.replace(\"'\", \"\")\n",
    "\n",
    "df['Date']  = pd.to_datetime(df['Date'], format='%b %y')\n",
    "df['Year'] = df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#currently all values are in strings, I want to convert the numerical values to integers, and have NA be pandas NaN\n",
    "\n",
    "assert ((df['Salary']==\"NA\").sum() ==0) #salary doesn't have any NA values, \n",
    "df['Salary'] = df['Salary'].str.replace(',', '').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ((df['Job Satisfaction']==\"NA\").sum() ==0)\n",
    "#try to convert Job Satisfaction to int, if fails then put NaN\n",
    "df['Job Satisfaction'] = pd.to_numeric(df['Job Satisfaction'], errors='coerce')\n",
    "\n",
    "#set Job Satisfaction to be a categorical feature\n",
    "df['Job Satisfaction'] = df['Job Satisfaction'].astype(int)\n",
    "\n",
    "df = df[df['Job Satisfaction'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when I did this 56 duplicates were removed\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a copy just in case\n",
    "df_old=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check type of all columns\n",
    "print(\"full time: \", df[df['Work Status']=='Full-time'].shape[0])\n",
    "print(\"part time: \", df[df['Work Status']==\"Part-time\"].shape[0])\n",
    "print(\"freelance: \", df[df['Work Status']==\"Freelance\"].shape[0])\n",
    "print(\"not specified: \", df[df['Work Status'].isna()].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To preserve as much data as possible, I convert individuals working fulltime and freelance with hourly income to yearly income by multiplying it by 40*52 hours a year. If you want to be more precise feel free to drop those in entirety. I drop part-time individuals.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the hourly income to annual income if working full time\n",
    "df_fulltime = df[df['Work Status']!=\"Part-time\"].copy()\n",
    "\n",
    "#TODO: should the hourly rate be extrapolated or just dropped?\n",
    "#df_fulltime[(df_fulltime[\"Salary Unit\"] == \"hour\") & (df_fulltime[\"Salary\"]>100000)]\n",
    "df_fulltime[\"Salary\"] = df_fulltime.apply(lambda x: x['Salary']*40*52 if x['Salary Unit']==\"hour\" and x['Work Status']==\"Full-time\" else x['Salary'], axis=1)\n",
    "\n",
    "\n",
    "#get rid of entries with annual income less than $10,000 (this is probably people who work much less than 40*52 hours a year)\n",
    "df_fulltime = df_fulltime[df_fulltime[\"Salary\"]>=10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I used the Nominatim package to find latitude and longitude for all locations in the surveys. No need to rerun, my results are saved in location_coordinates.csv</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from geopy.geocoders import Nominatim\n",
    "\n",
    "# # Initialize the geolocator\n",
    "# geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "# # Function to get coordinates\n",
    "# def get_coordinates(location):\n",
    "#   try:\n",
    "#     loc = geolocator.geocode(location)\n",
    "#     if loc:\n",
    "#       print(f\"Location: {location}, Latitude: {loc.latitude}, Longitude: {loc.longitude}\")\n",
    "#       return (loc.latitude, loc.longitude)\n",
    "#     else:\n",
    "#       print(f\"Location: {location}, Latitude: None, Longitude: None\")\n",
    "#       return (None, None)\n",
    "#   except:\n",
    "#     return (None, None)\n",
    "\n",
    "# # Get unique locations\n",
    "# unique_locations = df_fulltime['Location'].unique()\n",
    "\n",
    "# # Create a dictionary to store the coordinates for each unique location\n",
    "# location_coordinates = {location: get_coordinates(location) for location in unique_locations}\n",
    "\n",
    "# # Create new columns for latitude and longitude in the original DataFrame\n",
    "# df_fulltime['Latitude'] = df_fulltime['Location'].map(lambda x: location_coordinates[x][0])\n",
    "# df_fulltime['Longitude'] = df_fulltime['Location'].map(lambda x: location_coordinates[x][1])\n",
    "\n",
    "# import csv\n",
    "\n",
    "# # Define the CSV file name\n",
    "# csv_file = \"location_coordinates.csv\"\n",
    "\n",
    "# # Write the dictionary to a CSV file\n",
    "# with open(csv_file, mode='w', newline='') as file:\n",
    "#   writer = csv.writer(file)\n",
    "#   writer.writerow([\"Location\", \"Latitude\", \"Longitude\"])  # Write the header\n",
    "#   for location, coordinates in location_coordinates.items():\n",
    "#     writer.writerow([location, coordinates[0], coordinates[1]])  # Write the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the location coordinates from the CSV file\n",
    "location_df = pd.read_csv(\"location_coordinates.csv\")\n",
    "\n",
    "# Merge the location coordinates with the main DataFrame\n",
    "df_fulltime = df_fulltime.merge(location_df, on=\"Location\", how=\"left\")\n",
    "\n",
    "#drop the columns that are not needed\n",
    "#df_fulltime.drop(columns=[\"id\", \"Salary Unit\"], inplace=True)\n",
    "\n",
    "#replace \" People\" with \"\" in Firm Size\n",
    "df_fulltime['Firm Size'] = df_fulltime['Firm Size'].str.replace(\" People\", \"\")\n",
    "df_fulltime['Firm Size'] = df_fulltime['Firm Size'].str.replace(\"501 +\", \"501+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fulltime.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Initial analysis and cleaning</h4>\n",
    "<p>After limiting data to just fulltime workers, I take a closer look at the entries and get rid of more \"bad\" data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# df_fulltime[df_fulltime[\"Vacation Days\"]>100]\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df_fulltime[df_fulltime[\"Vacation Days\"]<100][\"Vacation Days\"].dropna(), bins=30, kde=True)\n",
    "plt.title(\"Distribution of Vacation Days\")\n",
    "plt.xlabel(\"Vacation Days\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the rows where \"Annual Bonus\" has things other than numbers and commas\n",
    "notnarows = df_fulltime[df_fulltime[\"Annual Bonus\"].notna()]\n",
    "invalid_bonus_rows = notnarows[notnarows[\"Annual Bonus\"].str.contains(r'[^0-9,]', regex=True)]\n",
    "invalid_bonus_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shanghai and stuggart are obviously wrong, so remove ids 5573 and 4576 from df_fulltime\n",
    "df_fulltime = df_fulltime[df_fulltime['id']!=5573]\n",
    "df_fulltime = df_fulltime[df_fulltime['id']!=8747]\n",
    "\n",
    "#do a conversion for the canadian using 1 CAD = 0.72 USD, rewrite id 17103's salary as salary*0.72\n",
    "df_fulltime.loc[df_fulltime['id']==17102, 'Salary'] = round(105000*0.72)\n",
    "df_fulltime.loc[df_fulltime['id']==17102, 'Salary Unit'] = \"year\"\n",
    "df_fulltime.loc[df_fulltime['id']==17102, 'Annual Bonus'] = str(round(8000*0.72))\n",
    "\n",
    "#conversion from 1 EUR to 1.08 USD\n",
    "df_fulltime.loc[df_fulltime['id']==4576, 'Annual Bonus'] = str(round(25000*1.08))\n",
    "df_fulltime.loc[df_fulltime['id']==3825, 'Annual Bonus'] = str(round(2000*1.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert annual bonus to numbers\n",
    "df_fulltime[\"Annual Bonus\"] = df_fulltime[\"Annual Bonus\"].str.replace(r'[^0-9]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The annual bonus also revealed some funky salary units, so I will correct these\n",
    "df_fulltime[\"Salary Unit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct the CAD\n",
    "df_fulltime.loc[df_fulltime['Salary Unit']==\"CADyear\",'Salary Unit'] = \"year\"\n",
    "df_fulltime.loc[df_fulltime['Salary Unit']==\"CADyear\",'Salary'] = round(df_fulltime.loc[df_fulltime['Salary Unit']==\"CADyear\",'Salary']*0.72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local currency seems to be just usd, so change it to year\n",
    "df_fulltime.loc[df_fulltime['Salary Unit']==\"localcurrencyyear\",'Salary Unit'] = \"year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the salary unit of CHF is in Switzerland, so this is a bad entry, I delete it\n",
    "print(df_fulltime.loc[df_fulltime['Salary Unit']==\"CHFyear\"])\n",
    "df_fulltime = df_fulltime[df_fulltime['id']!=3616]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the units should only be year and hour (hour kept to refer to those that were converted to annual)\n",
    "df_fulltime[\"Salary Unit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df_fulltime[df_fulltime[\"Annual Bonus\"]<15000][\"Annual Bonus\"].dropna(), bins=30, kde=True)\n",
    "plt.title(\"Distribution of Annual Bonus\")\n",
    "plt.xlabel(\"Annual Bonus\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Export to csv, this is used for d3.js</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip the US because otherwise very repetitive (all locations are in the us)\n",
    "df_fulltime['Location']=df_fulltime['Location'].str.replace(\", US\", \"\")\n",
    "\n",
    "df_fulltime.to_csv(\"241114_archinect_salaries_fulltime.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>More visualization (I did this to understand the data, not directly used in web viz)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot income distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df_fulltime[\"Salary\"], bins=100, kde=True)\n",
    "plt.title(\"Salary Distribution\")\n",
    "plt.xlabel(\"Salary\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot income distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#plot job satisfaction distribution (there is only values 0-10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df_fulltime['Job Satisfaction'], bins=9, kde=True)\n",
    "plt.title(\"Job Satisfaction Distribution\")\n",
    "plt.xlabel(\"Job Satisfaction\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, interactive_output, Dropdown, widgets\n",
    "\n",
    "#ignore future warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def plot_salary_by_column_by_year(column_name, filter_value):\n",
    "    df=df_fulltime\n",
    "    # Filter the DataFrame by the selected job title\n",
    "    if filter_value == 'All':\n",
    "        filtered_df = df\n",
    "    else:    \n",
    "        filtered_df = df[df[column_name] == filter_value]\n",
    "\n",
    "    # Calculate the median salary for each year\n",
    "    median_salary = filtered_df.groupby('Year')['Salary'].median().reset_index()\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(x='Year', y='Salary', data=filtered_df, showfliers=False) #hue=\"Year\", palette='Set3'\n",
    "    \n",
    "    # Move legend to the side\n",
    "    # plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), title='Year')\n",
    "\n",
    "    plt.plot(median_salary.index, median_salary['Salary'], color='red', marker='o', label='Median Salary')\n",
    "    \n",
    "    plt.title(f'Salary Distribution for {filter_value} by Year')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Salary')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()\n",
    "\n",
    "# Function to create the interactive plot with dynamic filter values\n",
    "def create_interactive_plot():\n",
    "    # Dropdown for selecting the column\n",
    "    column_name_dropdown = Dropdown(options=[\"Job Title\", \"Firm Type\"], description=\"Column\")\n",
    "    \n",
    "    # Create an empty filter dropdown that will be updated\n",
    "    filter_value_dropdown = Dropdown(description='Filter')\n",
    "    \n",
    "    # Function to update filter_value options based on selected column_name\n",
    "    def update_filter_value_options(*args):\n",
    "        selected_column = column_name_dropdown.value\n",
    "        unique_values = ['All'] + list(df[selected_column].unique())\n",
    "        filter_value_dropdown.options = unique_values\n",
    "\n",
    "    # Attach the update function to the column_name dropdown changes\n",
    "    column_name_dropdown.observe(update_filter_value_options, 'value')\n",
    "    \n",
    "    # Initialize filter dropdown with the default column selected\n",
    "    update_filter_value_options()\n",
    "\n",
    "    # Display the widgets and the plot\n",
    "    ui = widgets.VBox([column_name_dropdown, filter_value_dropdown])\n",
    "    out = interactive_output(plot_salary_by_column_by_year, {\n",
    "        'column_name': column_name_dropdown, \n",
    "        'filter_value': filter_value_dropdown\n",
    "    })\n",
    "    \n",
    "    display(ui, out)\n",
    "\n",
    "# Call the function to display the interactive plot\n",
    "create_interactive_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, Dropdown\n",
    "\n",
    "def plot_median_salary(column_name, n=15):\n",
    "    # Get the top N values by counts of people with that value\n",
    "    top_n_vals = df[column_name].value_counts().nlargest(n)\n",
    "    vals = top_n_vals.index\n",
    "\n",
    "    # Create a list to hold (value, median_salary) tuples for the legend\n",
    "    median_salaries = []\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Loop through each value and plot the median salary trend\n",
    "    for val in vals:\n",
    "        # Filter the DataFrame by the current value\n",
    "        filtered_df = df[df[column_name] == val]\n",
    "\n",
    "        # Calculate the median salary by year\n",
    "        salary_stats = filtered_df.groupby('Year')['Salary'].median().reset_index()\n",
    "\n",
    "        # Plot the median salary trend\n",
    "        line, = plt.plot(salary_stats['Year'], salary_stats['Salary'], marker='o', label=val)\n",
    "\n",
    "        # Store the overall median salary for the current value\n",
    "        overall_median = filtered_df['Salary'].median()\n",
    "        median_salaries.append((val, overall_median, line))\n",
    "\n",
    "    # Sort median salaries for the legend, but keep track of the original lines\n",
    "    sorted_median_salaries = sorted(median_salaries, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Create a custom legend based on the sorted median salaries\n",
    "    custom_legend = [f\"{val}: {median:.0f}\" for val, median, _ in sorted_median_salaries]\n",
    "    handles = [line for _, _, line in sorted_median_salaries]  # Extract lines for legend\n",
    "\n",
    "    # Plot settings\n",
    "    plt.title(f'Median Salary Trends by {column_name}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Median Salary')\n",
    "    plt.xticks(salary_stats['Year'])\n",
    "    plt.legend(handles, custom_legend, title=column_name, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.show()\n",
    "\n",
    "    #print(top_n_vals)\n",
    "\n",
    "# Call the function with interact\n",
    "interact(plot_median_salary, \n",
    "         n=15,\n",
    "         column_name=Dropdown(options=[\"Job Title\", \"Firm Type\", \"Firm Size\", \"Licensed\", \"Years of Experience\", \"Age\", \"Gender\", \"Job Satisfaction\"], description='Column Name'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sort(vals, column_name, sorting_column_name):\n",
    "    # Sort the job titles by mean satisfaction\n",
    "    if column_name == \"Years of Experience\":\n",
    "        experience_order = [\"< 1\", \"1\", \"2\", \"3\", \"3-5\", \"6-7\", \"8-10\", \"11-15\", \"16-20\", \"21-25\", \"26-30\", \"31-40\", \"> 40\"]\n",
    "\n",
    "        # Convert the 'Years of Experience' column to a categorical type with the specified order\n",
    "        vals['Years of Experience'] = pd.Categorical(vals['Years of Experience'], categories=experience_order, ordered=True)\n",
    "\n",
    "        # Sort the DataFrame by the 'Years of Experience' column\n",
    "        vals = vals.sort_values('Years of Experience')\n",
    "\n",
    "    elif column_name not in [\"Age\", \"Job Satisfaction\"]:\n",
    "        vals = vals.sort_values(by=sorting_column_name)\n",
    "    return vals\n",
    "\n",
    "def process_counts (df, column_name, n=20):\n",
    "        #if column name is in [\"Undergraduate School\", \"Graduate School\", \"Post-Graduate School\"] then we want to plot the top 20:\n",
    "    if column_name in [\"Undergraduate School\", \"Graduate School\", \"Location\"]:\n",
    "        response_counts = df[column_name].value_counts().nlargest(n).reset_index(name='Response Count')\n",
    "    else:\n",
    "        # Calculate the median salary across all years for each job title\n",
    "        response_counts = df.groupby(column_name).size().reset_index(name='Response Count')\n",
    "\n",
    "    # Sort the job titles by median salary\n",
    "    response_counts = sort(response_counts, column_name, \"Response Count\")\n",
    "\n",
    "    return response_counts\n",
    "\n",
    "def process_median_salary(df, column_name, n=20):\n",
    "    if column_name in [\"Undergraduate School\", \"Graduate School\", \"Location\"]:\n",
    "        # Calculate the top 20 locations by responder count\n",
    "        top_responses = df[column_name].value_counts().nlargest(n).index\n",
    "        # Filter the DataFrame to include only the top locations\n",
    "        filtered_df = df[df[column_name].isin(top_responses)]\n",
    "\n",
    "         # Calculate the median salary across all years for each job title\n",
    "        median_salary_per_job = filtered_df.groupby(column_name)['Salary'].median().reset_index()\n",
    "    else:\n",
    "        median_salary_per_job = df.groupby(column_name)['Salary'].median().reset_index()\n",
    "\n",
    "    # Sort the job titles by median salary\n",
    "    median_salary_per_job = sort(median_salary_per_job, column_name, \"Salary\")\n",
    "\n",
    "    return median_salary_per_job\n",
    "\n",
    "def process_mean_satisfaction(df, column_name, n=20):\n",
    "    if column_name in [\"Undergraduate School\", \"Graduate School\", \"Location\"]:\n",
    "        # Calculate the top 20 locations by responder count\n",
    "        top_responses = df[column_name].value_counts().nlargest(n).index\n",
    "        # Filter the DataFrame to include only the top locations\n",
    "        filtered_df = df[df[column_name].isin(top_responses)]\n",
    "\n",
    "         # Calculate the median salary across all years for each job title\n",
    "        mean_satisfaction_per_job = filtered_df.groupby(column_name)['Job Satisfaction'].mean().reset_index()\n",
    "    else:\n",
    "        mean_satisfaction_per_job = df.groupby(column_name)['Job Satisfaction'].mean().reset_index()\n",
    "\n",
    "    mean_satisfaction_per_job = sort(mean_satisfaction_per_job, column_name, \"Job Satisfaction\")\n",
    "\n",
    "    return mean_satisfaction_per_job\n",
    "\n",
    "def plot_response_by_column(df):\n",
    "\n",
    "    def plotting_func(column_name, feature_type = 'Response Count'):\n",
    "        if feature_type == 'Response Count':\n",
    "            response = process_counts(df, column_name)\n",
    "        elif feature_type == 'Salary':\n",
    "            response = process_median_salary(df, column_name)\n",
    "        else:\n",
    "            response = process_mean_satisfaction(df, column_name)\n",
    "\n",
    "\n",
    "        # Set up the figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Create a bar plot for the sorted median salaries\n",
    "        plt.bar(response[column_name], response[feature_type], color='skyblue')\n",
    "\n",
    "        # Plot settings\n",
    "        plt.title(f'{feature_type} by {column_name}')\n",
    "        plt.ylabel(feature_type)\n",
    "        plt.xlabel(column_name)\n",
    "        plt.xticks(rotation=45, ha='right',va='top')\n",
    "        plt.grid(True, axis='x')\n",
    "        plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "        plt.show()\n",
    "\n",
    "    return plotting_func\n",
    "\n",
    "# Call the function to plot\n",
    "interact(plot_response_by_column(df_fulltime), feature_type=Dropdown(options=[\"Response Count\", \"Salary\", \"Job Satisfaction\"]),column_name=Dropdown(options=[\"Job Satisfaction\", \"Job Title\", \"Firm Type\", \"Firm Size\", \"Licensed\", \"Years of Experience\", \"Age\", \"Gender\", \"Location\", \"Undergraduate School\", \"Graduate School\"], description='Column Name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, Dropdown\n",
    "\n",
    "def plot_mean_satisfaction_by_column(column_name):\n",
    "    df = df_fulltime  # Assuming df_fulltime is your DataFrame\n",
    "    \n",
    "    # Calculate the mean job satisfaction across the selected column\n",
    "    mean_satisfaction_per_job = df.groupby(column_name)['Job Satisfaction'].mean().reset_index()\n",
    "\n",
    "    # Conditional sorting: retain natural order for \"Age\" and \"Years of Experience\"\n",
    "    if column_name == \"Years of Experience\":\n",
    "        experience_order = [\"< 1\", \"1\", \"2\", \"3\", \"3-5\", \"6-7\", \"8-10\", \"11-15\", \"16-20\", \"21-25\", \"26-30\", \"31-40\", \"> 40\"]\n",
    "\n",
    "        # Convert the 'Years of Experience' column to a categorical type with the specified order\n",
    "        mean_satisfaction_per_job['Years of Experience'] = pd.Categorical(mean_satisfaction_per_job['Years of Experience'], categories=experience_order, ordered=True)\n",
    "\n",
    "        # Sort the DataFrame by the 'Years of Experience' column\n",
    "        mean_satisfaction_per_job = mean_satisfaction_per_job.sort_values('Years of Experience')\n",
    "\n",
    "    elif column_name !=\"Age\":\n",
    "        mean_satisfaction_per_job = mean_satisfaction_per_job.sort_values(by='Job Satisfaction')\n",
    "        \n",
    "\n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Create a horizontal bar plot for the mean job satisfaction\n",
    "    plt.bar(mean_satisfaction_per_job[column_name], mean_satisfaction_per_job['Job Satisfaction'], color='skyblue')\n",
    "\n",
    "    # Plot settings\n",
    "    plt.title(f'Mean Job Satisfaction by {column_name}')\n",
    "    plt.ylabel('Mean Job Satisfaction')\n",
    "    plt.xlabel(column_name)\n",
    "    plt.xticks(rotation=45, ha='right',va='top')\n",
    "    plt.grid(True, axis='x')\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot with an interactive dropdown\n",
    "interact(plot_mean_satisfaction_by_column, \n",
    "         column_name=Dropdown(options=[\"Job Title\", \"Firm Type\", \"Firm Size\", \"Licensed\", \n",
    "                                       \"Years of Experience\", \"Age\", \"Gender\"], \n",
    "                              description='Column Name'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact, Dropdown, Checkbox\n",
    "\n",
    "def plot_median_salary_by_column(column_name, grouped=False):\n",
    "    # Check if the user wants a grouped chart\n",
    "    if grouped:\n",
    "        # Calculate the median salary by column and gender\n",
    "        salary_data = df.groupby([column_name, 'Licensed'])['Salary'].median().reset_index()\n",
    "        \n",
    "        # Plotting grouped bar chart\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(data=salary_data, y='Salary', x=column_name, hue='Licensed', palette='Set2')\n",
    "        \n",
    "        # Plot settings\n",
    "        plt.title(f'Grouped Median Salary by {column_name}')\n",
    "        plt.xlabel('Median Salary')\n",
    "        plt.ylabel(column_name)\n",
    "        plt.grid(True, axis='x')\n",
    "        plt.legend(title='Gender')\n",
    "        \n",
    "    else:\n",
    "        # Calculate the median salary across all years for each category\n",
    "        median_salary_per_job = df.groupby(column_name)['Salary'].median().reset_index()\n",
    "\n",
    "        # Sort the categories by median salary\n",
    "        median_salary_per_job = median_salary_per_job.sort_values(by='Salary')\n",
    "\n",
    "        # Set up the figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Create a horizontal bar plot for the sorted median salaries\n",
    "        plt.bar(median_salary_per_job[column_name], median_salary_per_job['Salary'], color='skyblue')\n",
    "\n",
    "        # Plot settings\n",
    "        plt.title(f'Median Salary by {column_name}')\n",
    "        plt.ylabel('Median Salary')\n",
    "        plt.xlabel(column_name)\n",
    "        plt.grid(True, axis='x')\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot with an additional dropdown for grouping\n",
    "interact(plot_median_salary_by_column, \n",
    "         column_name=Dropdown(options=[\"Job Title\", \"Firm Type\", \"Firm Size\", \"Licensed\", \"Years of Experience\", \"Age\", \"Job Satisfaction\"], description='Column Name'),\n",
    "         grouped=Checkbox(value=False, description='Show Grouped Bar Chart'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_matrices(df):\n",
    "    # First, ensure 'Years of Experience' and 'Firm Type' are categorical\n",
    "    experience_order = [\"< 1\", \"1\", \"2\", \"3\", \"3-5\", \"6-7\", \"8-10\", \"11-15\", \"16-20\", \"21-25\", \"26-30\", \"31-40\", \"> 40\"]\n",
    "\n",
    "    df['Years of Experience'] = pd.Categorical(df['Years of Experience'], categories=experience_order, ordered=True)\n",
    "    df['Firm Type'] = pd.Categorical(df['Firm Type'])\n",
    "\n",
    "    # Matrix 1: Job Satisfaction (mean)\n",
    "    job_satisfaction_matrix = df.pivot_table(index='Firm Type', columns='Years of Experience', \n",
    "                                             values='Job Satisfaction', aggfunc='mean')\n",
    "\n",
    "    # Matrix 2: Salary (median)\n",
    "    salary_matrix = df.pivot_table(index='Firm Type', columns='Years of Experience', \n",
    "                                   values='Salary', aggfunc='median')\n",
    "\n",
    "    # Matrix 3: Response Count\n",
    "    response_count_matrix = df.pivot_table(index='Firm Type', columns='Years of Experience', \n",
    "                                           values='Job Satisfaction', aggfunc='count')\n",
    "\n",
    "    return job_satisfaction_matrix, salary_matrix, response_count_matrix\n",
    "\n",
    "# Sample usage\n",
    "job_satisfaction_matrix, salary_matrix, response_count_matrix = create_matrices(df_fulltime)\n",
    "\n",
    "# Display the matrices\n",
    "print(\"Job Satisfaction Matrix:\")\n",
    "print(job_satisfaction_matrix)\n",
    "\n",
    "print(\"\\nSalary Matrix:\")\n",
    "print(salary_matrix)\n",
    "\n",
    "print(\"\\nResponse Count Matrix:\")\n",
    "print(response_count_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_mapping = {\n",
    "\n",
    "      '< 1':0.5,\n",
    "      '1':1,\n",
    "      '2':2,\n",
    "      '3':3,\n",
    "      '3-5':4,\n",
    "      '6-7':6.5,\n",
    "      '8-10':9,\n",
    "      '11-15':13,\n",
    "      '16-20':18,\n",
    "      '21-25':23,   \n",
    "      '26-30':28,  \n",
    "      '31-40':35.5,\n",
    "      '> 40':40\n",
    "}\n",
    "\n",
    "def plot_experience_vs_age_gender(df):\n",
    "    \n",
    "\n",
    "    # Map years of experience to median values\n",
    "    df['Experience_Median'] = df['Years of Experience'].map(experience_mapping)\n",
    "    #set to float\n",
    "    df['Experience_Median'] = df[\"Experience_Median\"].astype(float)\n",
    "\n",
    "    # Group by Age and Gender, then calculate the mean of the median experience values\n",
    "    mean_experience = df.groupby(['Age', 'Gender'])['Experience_Median'].mean().reset_index()\n",
    "\n",
    "    # Pivot to make it suitable for a grouped bar plot\n",
    "    experience_pivot = mean_experience.pivot(index='Age', columns='Gender', values='Experience_Median')\n",
    "\n",
    "    # Plotting\n",
    "    experience_pivot.plot(kind='bar', figsize=(10, 6), color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "    plt.title('Average Years of Experience by Age and Gender')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Average Years of Experience')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_experience_vs_age_gender(df_fulltime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_experience_vs_age_gender_stream(df):\n",
    "    # Map years of experience to median values\n",
    "    df['Experience_Median'] = df['Years of Experience'].map(experience_mapping)\n",
    "    df['Experience_Median'] = df[\"Experience_Median\"].astype(float)\n",
    "\n",
    "    # Group by Age and Gender, calculate the mean of the median experience values and count of respondents\n",
    "    grouped_data = df.groupby(['Age', 'Gender']).agg({\n",
    "        'Experience_Median': 'mean', \n",
    "        'Gender': 'count'  # count of respondents\n",
    "    }).rename(columns={'Gender': 'Respondent_Count'}).reset_index()\n",
    "\n",
    "    # Pivot to get experience data in the right format for plotting\n",
    "    experience_pivot = grouped_data.pivot(index='Age', columns='Gender', values='Experience_Median')\n",
    "    count_pivot = grouped_data.pivot(index='Age', columns='Gender', values='Respondent_Count')\n",
    "\n",
    "    # Plot settings\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Create the stream plot effect by filling between lines, varying thickness with respondent count\n",
    "    genders = ['Male', 'Female', 'Other']\n",
    "    colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "    for i, gender in enumerate(genders):\n",
    "        if gender in experience_pivot.columns:\n",
    "            experience_vals = experience_pivot[gender].values\n",
    "            respondent_counts = count_pivot[gender].fillna(0).values\n",
    "\n",
    "            # Normalize the respondent counts to scale the thickness\n",
    "            respondent_counts = respondent_counts / respondent_counts.max() * 5  # scale factor for thickness\n",
    "\n",
    "            # Create a \"stream\" effect by filling between lines with variable width\n",
    "            plt.fill_between(experience_pivot.index, experience_vals - respondent_counts / 2, \n",
    "                             experience_vals + respondent_counts / 2, alpha=0.6, color=colors[i], label=gender)\n",
    "\n",
    "    # Plot settings\n",
    "    plt.title('Stream of Average Years of Experience by Age and Gender (Thickness = Number of Respondents)')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Average Years of Experience')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.legend(title='Gender', loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#df_filtered = df_fulltime[~df_fulltime['Age'].isin(['61-65','66-70', '71-103'])]\n",
    "plot_experience_vs_age_gender_stream(df_fulltime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fulltime['Years of Experience'].map(experience_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(matrix, title, cmap=\"Blues\", fmt='.0f'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(matrix, annot=True, cmap=cmap, fmt=fmt, linewidths=0.5)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Years of Experience')\n",
    "    plt.ylabel('Firm Type')\n",
    "    plt.show()\n",
    "\n",
    "# Sample usage\n",
    "job_satisfaction_matrix, salary_matrix, response_count_matrix = create_matrices(df_fulltime)\n",
    "\n",
    "# Visualize the matrices with color\n",
    "plot_heatmap(job_satisfaction_matrix, 'Job Satisfaction Heatmap', cmap='RdYlGn', fmt='.2f')\n",
    "plot_heatmap(salary_matrix, 'Salary Heatmap', cmap='YlGnBu')\n",
    "plot_heatmap(response_count_matrix, 'Response Count Heatmap', cmap='Oranges')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4620-A3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
